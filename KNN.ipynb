{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download .csv file with the calculated features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "# from PIL import Image\n",
    "# from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features_csv = pd.read_csv('features_file_resnet.csv')\n",
    "train_labels = pd.read_csv(\"train_labels.csv\", index_col=\"id\")\n",
    "\n",
    "train_features_csv.tail(n=4)\n",
    "\n",
    "species_labels = sorted(train_labels.columns.unique())\n",
    "species_labels\n",
    "\n",
    "small_train_labels = train_features_csv[:, 0]\n",
    "small_train_labels.tail(n=4)\n",
    "small_train_features = train_features_csv[:, 1:]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split into train and evaluation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_features_random = train_features_csv.sample(random_state=1)\n",
    "y = train_features_random[:, 0]\n",
    "x = train_features_random[:, 1:]\n",
    "\n",
    "# note that we are casting the species labels to an indicator/dummy matrix\n",
    "x_train, x_eval, y_train, y_eval = train_test_split(\n",
    "    x, y, stratify=y, test_size=0.25 #TESTAR o stratify\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.head()\n",
    "y_train.head()\n",
    "x_train.shape, y_train.shape, x_eval.shape, y_eval.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement the K-Nearest Neighbors Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step-1: Select the number K of the neighbors\n",
    "K = 5\n",
    "#Step-2: Calculate the Euclidean distance of K number of neighbors\n",
    "all_distances = []\n",
    "knn_distances = []\n",
    "for sample in x_eval:\n",
    "    distance = sum((sample-x_train)**2)\n",
    "    all_distances = (distance)\n",
    "    knn_distances = sorted(all_distances, reverse=True)\n",
    "    knn_distances = knn_distances[0:K, :]\n",
    "\n",
    "\n",
    "#Step-3: Take the K nearest neighbors as per the calculated Euclidean distance.\n",
    "\n",
    "#Step-4: Among these k neighbors, count the number of the data points in each category.\n",
    "#Step-5: Assign the new data points to that category for which the number of the neighbor is maximum.\n",
    "#Step-6: Our model is ready."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sklearn function to KNN\n",
    "Source: https://scikit-learn.org/stable/auto_examples/neighbors/plot_classification.html#sphx-glr-auto-examples-neighbors-plot-classification-py\n",
    "\n",
    "https://www.geeksforgeeks.org/k-nearest-neighbor-algorithm-in-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn import neighbors, datasets\n",
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "K = 15\n",
    "\n",
    "# import some data to play with\n",
    "x_train, x_eval, y_train, y_eval\n",
    "\n",
    "X = x_train\n",
    "y = y_train\n",
    "\n",
    "for weights in [\"uniform\", \"distance\"]:\n",
    "    # we create an instance of Neighbours Classifier and fit the data.\n",
    "    clf = neighbors.KNeighborsClassifier(K, weights=weights)\n",
    "    clf.fit(X, y)\n",
    "\n",
    "# Predict on dataset which model has not seen before\n",
    "print(clf.predict(x_eval))\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "print(knn.score(X_test, y_test))\n",
    "\n",
    "print(classification_report(y_eval, clf.predict(x_eval),\n",
    "\ttarget_names=species_labels))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8 (tags/v3.7.8:4b47a5b6ba, Jun 28 2020, 08:53:46) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0a54084e6b208ee8d1ce3989ffc20924477a5f55f5a43e22e699a6741623861e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
